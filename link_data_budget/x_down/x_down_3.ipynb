{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb91ac3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41313039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote CSV -> Endurosat_X-band_link_margin_vs_elevation.csv\n",
      "Wrote PNG -> Endurosat_X-band_link_margin_vs_elevation.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Compute Endurosat X-band link margin vs. elevation for two altitudes and\n",
    "export both a PNG plot and a CSV table.\n",
    "\n",
    "Inputs pulled from CSV (Endurosat X-band column):\n",
    "- selected_carrier_frequency [GHz]\n",
    "- tx_power [W]\n",
    "- peak_boresight_antenna_gain [dBi]\n",
    "- interconnect_losses_gains [dB]  (positive = loss)\n",
    "- atmospheric_attenuation, rain_attenuation, scintillation_loss,\n",
    "  polarisation_loss, other_propagation_losses [dB]\n",
    "- g_t [dB/K]\n",
    "- data_rate_in_db_hz [dB-Hz]\n",
    "- codmod_inferred_required_eb_n0 [dB]\n",
    "- other_overall_link_losses, gain_rolloff_loss_at_pointing_error [dB]\n",
    "\n",
    "Outputs:\n",
    "- ./Endurosat_X-band_link_margin_vs_elevation.csv\n",
    "- ./Endurosat_X-band_link_margin_vs_elevation.png\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EARTH_RADIUS_KM = 6371.0\n",
    "TARGET_COLUMN = \"Endurosat X-band\"\n",
    "\n",
    "# -------- helpers --------\n",
    "def to_float(x):\n",
    "    try:\n",
    "        return float(str(x).replace(\"%\", \"\").strip())\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def resolve_csv_path(cli_csv: str | None):\n",
    "    if cli_csv and cli_csv.lower().endswith(\".csv\") and Path(cli_csv).is_file():\n",
    "        return cli_csv\n",
    "    for p in [\"./x_down_info.csv\",\n",
    "              os.path.expanduser(\"~/Downloads/x_down_info.csv\"),\n",
    "              \"/mnt/data/x_down_info.csv\"]:\n",
    "        if Path(p).is_file():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"CSV not found. Pass a path explicitly (e.g. --csv C:\\\\path\\\\x_down_info.csv) \"\n",
    "        \"or place x_down_info.csv in the current folder.\"\n",
    "    )\n",
    "\n",
    "def get_var(df: pd.DataFrame, varname: str, default=None):\n",
    "    s = df.loc[df[\"python_variable\"] == varname, TARGET_COLUMN]\n",
    "    return to_float(s.iloc[0]) if not s.empty else default\n",
    "\n",
    "def slant_range_km(alt_km: float, elev_deg: float) -> float:\n",
    "    e = math.radians(elev_deg)\n",
    "    R = EARTH_RADIUS_KM\n",
    "    H = R + alt_km\n",
    "    return -R * math.sin(e) + math.sqrt((R * math.sin(e)) ** 2 + H ** 2 - R ** 2)\n",
    "\n",
    "def fspl_db(range_km: float, freq_ghz: float) -> float:\n",
    "    # Standard: 92.45 + 20log10(R[km]) + 20log10(f[GHz])\n",
    "    return 92.45 + 20 * math.log10(range_km) + 20 * math.log10(freq_ghz)\n",
    "\n",
    "def eirp_dbw(P_w: float, G_tx_dbi: float, L_tx_db: float) -> float:\n",
    "    return 10 * math.log10(P_w) + (G_tx_dbi or 0.0) - (L_tx_db or 0.0)\n",
    "\n",
    "def cn0_dbhz(eirp_dbw: float, L_total_db: float, G_T_dbk: float,\n",
    "             k_val: float = 1.38e-23, extra_losses_db: float = 0.0) -> float:\n",
    "    k_db = 10 * math.log10(k_val)\n",
    "    return eirp_dbw - L_total_db + (G_T_dbk or 0.0) - k_db - (extra_losses_db or 0.0)\n",
    "\n",
    "# -------- main compute --------\n",
    "def compute_table(csv_path: str,\n",
    "                  altitudes=(500, 600),\n",
    "                  elevations=(0, 5, 10, 15, 20)) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # constants from CSV\n",
    "    f_ghz = get_var(df, \"selected_carrier_frequency\")\n",
    "    tx_power_w = get_var(df, \"tx_power\")\n",
    "    Gtx_dbi = get_var(df, \"peak_boresight_antenna_gain\")\n",
    "    Ltx_db = get_var(df, \"interconnect_losses_gains\", 0.0)\n",
    "\n",
    "    atm = get_var(df, \"atmospheric_attenuation\", 0.0)\n",
    "    rain = get_var(df, \"rain_attenuation\", 0.0)\n",
    "    scint = get_var(df, \"scintillation_loss\", 0.0)\n",
    "    pol = get_var(df, \"polarisation_loss\", 0.0)\n",
    "    other_prop = get_var(df, \"other_propagation_losses\", 0.0)\n",
    "\n",
    "    G_T = get_var(df, \"g_t\")\n",
    "    Rb_dBHz = get_var(df, \"data_rate_in_db_hz\")\n",
    "    EbN0_req = get_var(df, \"codmod_inferred_required_eb_n0\", 0.0)\n",
    "    other_overall = get_var(df, \"other_overall_link_losses\", 0.0)\n",
    "    rolloff = get_var(df, \"gain_rolloff_loss_at_pointing_error\", 0.0)\n",
    "\n",
    "    rows = []\n",
    "    for alt in altitudes:\n",
    "        for el in elevations:\n",
    "            sr_km = slant_range_km(alt, el)\n",
    "            Lfs = fspl_db(sr_km, f_ghz)\n",
    "            Ltotal = Lfs + atm + rain + scint + pol + other_prop\n",
    "            eirp = eirp_dbw(tx_power_w, Gtx_dbi, Ltx_db)\n",
    "            cn0 = cn0_dbhz(eirp, Ltotal, G_T, 1.38e-23, other_overall + rolloff)\n",
    "            ebn0 = cn0 - Rb_dBHz\n",
    "            margin = ebn0 - EbN0_req\n",
    "\n",
    "            rows.append({\n",
    "                \"orbit_altitude_km\": alt,\n",
    "                \"elevation_deg\": el,\n",
    "                \"slant_range_km\": sr_km,\n",
    "                \"fspl_db\": Lfs,\n",
    "                \"total_prop_loss_db\": Ltotal,\n",
    "                \"eirp_dbw\": eirp,\n",
    "                \"cn0_dbhz\": cn0,\n",
    "                \"ebn0_db\": ebn0,\n",
    "                \"link_margin_db\": margin,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def make_plot(df_out: pd.DataFrame, png_path: str):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for alt in sorted(df_out[\"orbit_altitude_km\"].unique()):\n",
    "        subset = df_out[df_out[\"orbit_altitude_km\"] == alt].sort_values(\"elevation_deg\")\n",
    "        plt.plot(subset[\"elevation_deg\"], subset[\"link_margin_db\"], marker=\"o\", label=f\"{int(alt)} km\")\n",
    "    plt.title(\"Link Margin vs Elevation for Endurosat X-band\")\n",
    "    plt.xlabel(\"Elevation (degrees)\")\n",
    "    plt.ylabel(\"Link Margin (dB)\")\n",
    "    plt.xticks(sorted(df_out[\"elevation_deg\"].unique()))\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(png_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Generate Link Margin vs Elevation plot and CSV.\")\n",
    "    parser.add_argument(\"--csv\", help=\"Path to x_down_info.csv\")\n",
    "    parser.add_argument(\"--out-csv\", default=\"Endurosat_X-band_link_margin_vs_elevation.csv\")\n",
    "    parser.add_argument(\"--out-png\", default=\"Endurosat_X-band_link_margin_vs_elevation.png\")\n",
    "    parser.add_argument(\"--alts\", nargs=\"*\", type=float, default=[500, 600],\n",
    "                        help=\"Altitudes in km (space-separated)\")\n",
    "    parser.add_argument(\"--elevs\", nargs=\"*\", type=float, default=[0, 5, 10, 15, 20],\n",
    "                        help=\"Elevations in degrees (space-separated)\")\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    csv_path = resolve_csv_path(args.csv)\n",
    "\n",
    "    df_out = compute_table(csv_path, altitudes=args.alts, elevations=args.elevs)\n",
    "    df_out.to_csv(args.out_csv, index=False)\n",
    "    make_plot(df_out, args.out_png)\n",
    "\n",
    "    print(f\"Wrote CSV -> {args.out_csv}\")\n",
    "    print(f\"Wrote PNG -> {args.out_png}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f962e476",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25d39698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500 km] time≥thr: 396.9s  data: 3725.6 MiB\n",
      "[600 km] time≥thr: 422.5s  data: 3181.9 MiB\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Notebook/CLI friendly pass data budget generator.\n",
    "\n",
    "- If run with CLI args, behaves like before.\n",
    "- If run with *no* args (e.g., pasted into a Jupyter cell), it:\n",
    "  * looks for Endurosat_X-band_link_margin_vs_elevation.csv and x_down_info.csv\n",
    "    in ./ or /mnt/data\n",
    "  * finds all altitudes in the link CSV\n",
    "  * writes pass_data_budget_<alt>km.csv for each altitude\n",
    "\"\"\"\n",
    "\n",
    "import argparse, math, sys, os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "MU_EARTH = 398600.4418  # km^3/s^2\n",
    "R_EARTH = 6371.0        # km\n",
    "\n",
    "def find_file(name):\n",
    "    for p in [Path(name), Path(\"/mnt/data\")/name]:\n",
    "        if p.is_file():\n",
    "            return str(p)\n",
    "    return None\n",
    "\n",
    "def get_supported_rate(info_csv: str):\n",
    "    df = pd.read_csv(info_csv)\n",
    "    s = df.loc[df[\"python_variable\"].astype(str)==\"supported_user_data_rate\"]\n",
    "    if s.empty:\n",
    "        s = df[df[\"Parameter\"].astype(str).str.contains(\"Supported user data rate\", case=False, na=False)]\n",
    "    if s.empty:\n",
    "        raise ValueError(\"Could not find 'Supported user data rate' in x_down_info.csv\")\n",
    "    val = s.iloc[0][\"Endurosat X-band\"]\n",
    "    units = s.iloc[0][\"Units\"] if \"Units\" in df.columns else \"\"\n",
    "    rate_val = float(str(val).strip())\n",
    "    unit_str = (units or \"\").lower()\n",
    "    if \"mb\" in unit_str:  bps, pretty = rate_val*1e6, \"Mb/s\"\n",
    "    elif \"kb\" in unit_str: bps, pretty = rate_val*1e3, \"kb/s\"\n",
    "    elif \"b/s\" in unit_str or \"bps\" in unit_str: bps, pretty = rate_val, \"b/s\"\n",
    "    else: bps, pretty = rate_val*1e6, \"Mb/s (assumed)\"\n",
    "    return bps, pretty\n",
    "\n",
    "def central_angle_from_slant(range_km: float, alt_km: float) -> float:\n",
    "    H = R_EARTH + alt_km\n",
    "    rho = range_km\n",
    "    cos_theta = (R_EARTH*R_EARTH + H*H - rho*rho) / (2*R_EARTH*H)\n",
    "    return math.acos(max(-1.0, min(1.0, cos_theta)))\n",
    "\n",
    "def mean_motion_rad_s(alt_km: float) -> float:\n",
    "    a = R_EARTH + alt_km\n",
    "    return math.sqrt(MU_EARTH / (a*a*a))\n",
    "\n",
    "def build_budget(link_csv: str, info_csv: str, alt_km: float,\n",
    "                 emin: float | None, margin_min: float, out_csv: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(link_csv)\n",
    "    need = {\"orbit_altitude_km\",\"elevation_deg\",\"link_margin_db\",\"slant_range_km\"}\n",
    "    if not need.issubset(df.columns):\n",
    "        raise ValueError(f\"link CSV missing columns: {need - set(df.columns)}\")\n",
    "    dfa = df[df[\"orbit_altitude_km\"].astype(float)==float(alt_km)].copy()\n",
    "    if dfa.empty:\n",
    "        raise ValueError(f\"No rows for orbit_altitude_km={alt_km}\")\n",
    "    dfa.sort_values(\"elevation_deg\", inplace=True)\n",
    "    bps, unit_str = get_supported_rate(info_csv)\n",
    "    if emin is None:\n",
    "        emin = float(dfa[\"elevation_deg\"].min())\n",
    "\n",
    "    e = dfa[\"elevation_deg\"].to_list()\n",
    "    m = dfa[\"link_margin_db\"].to_list()\n",
    "    r = dfa[\"slant_range_km\"].to_list()\n",
    "    theta = [central_angle_from_slant(x, alt_km) for x in r]\n",
    "    n = mean_motion_rad_s(alt_km)\n",
    "\n",
    "    rows = []\n",
    "    for i in range(len(e)-1):\n",
    "        e0, e1 = e[i], e[i+1]\n",
    "        m0, m1 = m[i], m[i+1]\n",
    "        th0, th1 = theta[i], theta[i+1]\n",
    "        if max(e0,e1) < emin: continue\n",
    "        e_start, e_end = max(min(e0,e1), emin), max(e0,e1)\n",
    "        if e_end <= e_start: continue\n",
    "\n",
    "        def lerp(x0,y0,x1,y1,x):\n",
    "            t=(x-x0)/(x1-x0); return y0+t*(y1-y0)\n",
    "\n",
    "        if e1 < e0:  # ensure ascending\n",
    "            e0,e1 = e1,e0; m0,m1 = m1,m0; th0,th1 = th1,th0\n",
    "\n",
    "        th_start = lerp(e0,th0,e1,th1,e_start)\n",
    "        th_end   = lerp(e0,th0,e1,th1,e_end)\n",
    "        m_start  = lerp(e0,m0, e1,m1, e_start)\n",
    "        m_end    = lerp(e0,m0, e1,m1, e_end)\n",
    "\n",
    "        dtheta = max(0.0, th_start - th_end)\n",
    "        bin_time_s = 2.0 * dtheta / n  # rise+set\n",
    "\n",
    "        usable_fraction = 1.0\n",
    "        if (m_start < margin_min) and (m_end < margin_min):\n",
    "            usable_fraction = 0.0\n",
    "        elif (m_start < margin_min) or (m_end < margin_min):\n",
    "            if m_end != m_start:\n",
    "                e_cross = e_start + (margin_min - m_start) * (e_end - e_start) / (m_end - m_start)\n",
    "                usable_fraction = (e_end - e_cross) / (e_end - e_start) if e_start <= e_cross <= e_end else (1.0 if m_end >= margin_min else 0.0)\n",
    "            else:\n",
    "                usable_fraction = 0.0 if m_start < margin_min else 1.0\n",
    "\n",
    "        data_bits = bps * bin_time_s * usable_fraction\n",
    "        data_mib  = data_bits / (1024*1024*8)\n",
    "\n",
    "        rows.append({\n",
    "            \"alt_km\": float(alt_km),\n",
    "            \"elev_start_deg\": float(e_start),\n",
    "            \"elev_end_deg\": float(e_end),\n",
    "            \"theta_start_deg\": math.degrees(th_start),\n",
    "            \"theta_end_deg\": math.degrees(th_end),\n",
    "            \"bin_time_s\": bin_time_s,\n",
    "            \"margin_start_db\": m_start,\n",
    "            \"margin_end_db\": m_end,\n",
    "            \"usable_fraction\": usable_fraction,\n",
    "            \"data_bits\": data_bits,\n",
    "            \"data_MiB\": data_mib,\n",
    "            \"rate_bps\": bps,\n",
    "            \"rate_unit\": unit_str,\n",
    "        })\n",
    "\n",
    "    out = pd.DataFrame(rows)\n",
    "    out.to_csv(out_csv, index=False)\n",
    "    print(f\"[{int(alt_km)} km] time≥thr: {out['bin_time_s'].sum():.1f}s  data: {out['data_MiB'].sum():.1f} MiB\")\n",
    "    return out\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Create data budget for a pass from two CSVs.\")\n",
    "    parser.add_argument(\"--link-csv\", required=False, help=\"Path to Endurosat_X-band_link_margin_vs_elevation.csv\")\n",
    "    parser.add_argument(\"--info-csv\", required=False, help=\"Path to x_down_info.csv\")\n",
    "    parser.add_argument(\"--alt-km\", type=float, required=False, help=\"Orbit altitude to use\")\n",
    "    parser.add_argument(\"--emin\", type=float, default=None, help=\"Minimum elevation (deg)\")\n",
    "    parser.add_argument(\"--margin-min\", type=float, default=0.0, help=\"Minimum link margin counted (dB)\")\n",
    "    parser.add_argument(\"--out-csv\", required=False, help=\"Output CSV path\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # If no args given, auto mode (nice for notebooks)\n",
    "    if len(sys.argv) == 1 or (args.link_csv is None and args.info_csv is None):\n",
    "        link_csv = find_file(\"Endurosat_X-band_link_margin_vs_elevation.csv\")\n",
    "        info_csv = find_file(\"x_down_info.csv\")\n",
    "        if not link_csv or not info_csv:\n",
    "            raise SystemExit(\"Auto-mode couldn't find the CSVs. Put them next to the script or pass --link-csv/--info-csv.\")\n",
    "        df = pd.read_csv(link_csv)\n",
    "        alts = sorted(set(df[\"orbit_altitude_km\"]))\n",
    "        for alt in alts:\n",
    "            out_csv = f\"pass_data_budget_{int(alt)}km.csv\"\n",
    "            build_budget(link_csv, info_csv, float(alt), args.emin, args.margin_min, out_csv)\n",
    "        return\n",
    "\n",
    "    # CLI mode\n",
    "    if not all([args.link_csv, args.info_csv, args.alt_km, args.out_csv]):\n",
    "        parser.error(\"the following arguments are required: --link-csv, --info-csv, --alt-km, --out-csv\")\n",
    "\n",
    "    build_budget(args.link_csv, args.info_csv, args.alt_km, args.emin, args.margin_min, args.out_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2e1a72",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fff39a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500 km] base 396.9s → scaled 600.0s | data 5905.5 MB → pass_data_budget_500km_scaled_10min.csv\n",
      "[600 km] base 422.5s → scaled 600.0s | data 4738.2 MB → pass_data_budget_600km_scaled_10min.csv\n",
      "Wrote cumulative plot → pass_data_budget_scaled_10min_cumulative.png\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>alt_km</th>\n",
       "      <th>base_time_s</th>\n",
       "      <th>scaled_time_s</th>\n",
       "      <th>scaled_MB</th>\n",
       "      <th>scale_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pass_data_budget_500km.csv</td>\n",
       "      <td>500</td>\n",
       "      <td>396.905248</td>\n",
       "      <td>600.0</td>\n",
       "      <td>5905.492015</td>\n",
       "      <td>1.511696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pass_data_budget_600km.csv</td>\n",
       "      <td>600</td>\n",
       "      <td>422.499347</td>\n",
       "      <td>600.0</td>\n",
       "      <td>4738.196618</td>\n",
       "      <td>1.420121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         file  alt_km  base_time_s  scaled_time_s  \\\n",
       "0  pass_data_budget_500km.csv     500   396.905248          600.0   \n",
       "1  pass_data_budget_600km.csv     600   422.499347          600.0   \n",
       "\n",
       "     scaled_MB  scale_factor  \n",
       "0  5905.492015      1.511696  \n",
       "1  4738.196618      1.420121  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Config ---\n",
    "TARGET_DURATION_S = 600.0   # 10 minutes\n",
    "OUTDIR = Path(\".\")\n",
    "FILES = None                # or like [\"pass_data_budget_500km.csv\", ...]\n",
    "# ---------------\n",
    "\n",
    "def find_pass_files():\n",
    "    pats = [Path(\".\").glob(\"pass_data_budget_*km.csv\"),\n",
    "            Path(\"/mnt/data\").glob(\"pass_data_budget_*km.csv\")]\n",
    "    files = []\n",
    "    for g in pats:\n",
    "        for p in g:\n",
    "            if p.is_file() and p.suffix.lower()==\".csv\" and \"pass_data_budget_\" in p.name:\n",
    "                files.append(p.resolve())\n",
    "    seen, uniq = set(), []\n",
    "    for p in files:\n",
    "        if p not in seen:\n",
    "            uniq.append(p); seen.add(p)\n",
    "    return uniq\n",
    "\n",
    "def scale_one(path: Path, duration_s: float):\n",
    "    df = pd.read_csv(path)\n",
    "    required = {\"bin_time_s\", \"rate_bps\", \"usable_fraction\", \"alt_km\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        print(f\"⚠️  Skipping {path.name}: missing {missing}\")\n",
    "        return None, None\n",
    "\n",
    "    base_time = float(df[\"bin_time_s\"].sum())\n",
    "    if base_time <= 0:\n",
    "        print(f\"⚠️  Skipping {path.name}: total bin_time_s is zero\")\n",
    "        return None, None\n",
    "\n",
    "    scale = duration_s / base_time\n",
    "    d = df.copy()\n",
    "    d[\"bin_time_s_scaled\"] = d[\"bin_time_s\"] * scale\n",
    "    d[\"data_bits_scaled\"]  = d[\"rate_bps\"] * d[\"bin_time_s_scaled\"] * d[\"usable_fraction\"]\n",
    "\n",
    "    # Megabytes (decimal) and Mebibytes (binary)\n",
    "    d[\"data_MB_scaled\"]  = d[\"data_bits_scaled\"] / (8 * 1e6)\n",
    "    d[\"data_MiB_scaled\"] = d[\"data_bits_scaled\"] / (8 * 1024**2)\n",
    "\n",
    "    # Cumulative for plotting\n",
    "    d[\"cum_time_s_scaled\"] = d[\"bin_time_s_scaled\"].cumsum()\n",
    "    d[\"cum_MB_scaled\"]     = d[\"data_MB_scaled\"].cumsum()\n",
    "\n",
    "    alt = int(round(d[\"alt_km\"].iloc[0]))\n",
    "    summary = {\n",
    "        \"file\": path.name,\n",
    "        \"alt_km\": alt,\n",
    "        \"base_time_s\": base_time,\n",
    "        \"scaled_time_s\": float(d[\"bin_time_s_scaled\"].sum()),\n",
    "        \"scaled_MB\": float(d[\"data_MB_scaled\"].sum()),\n",
    "        \"scale_factor\": scale,\n",
    "    }\n",
    "    return d, summary\n",
    "\n",
    "paths = [Path(p) for p in FILES] if FILES else find_pass_files()\n",
    "if not paths:\n",
    "    raise SystemExit(\"No pass_data_budget_*km.csv files found.\")\n",
    "\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "scaled_list, summaries = [], []\n",
    "for p in paths:\n",
    "    d, s = scale_one(p, TARGET_DURATION_S)\n",
    "    if d is None: \n",
    "        continue\n",
    "    minutes = int(round(TARGET_DURATION_S/60))\n",
    "    alt = s[\"alt_km\"]\n",
    "    out_csv = OUTDIR / f\"pass_data_budget_{alt}km_scaled_{minutes}min.csv\"\n",
    "    d.to_csv(out_csv, index=False)\n",
    "    scaled_list.append(d)\n",
    "    summaries.append(s)\n",
    "    print(f\"[{alt} km] base {s['base_time_s']:.1f}s → scaled {s['scaled_time_s']:.1f}s | \"\n",
    "          f\"data {s['scaled_MB']:.1f} MB → {out_csv.name}\")\n",
    "\n",
    "# Combined cumulative MB vs time\n",
    "if scaled_list:\n",
    "    plt.figure(figsize=(8,6))\n",
    "    for d in scaled_list:\n",
    "        alt = int(round(d[\"alt_km\"].iloc[0]))\n",
    "        plt.plot(d[\"cum_time_s_scaled\"], d[\"cum_MB_scaled\"], marker=\"o\", label=f\"{alt} km\")\n",
    "    plt.title(f\"Cumulative Data vs Time (Scaled to {int(round(TARGET_DURATION_S/60))}-minute Pass)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Cumulative Data (MB)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    png_path = OUTDIR / f\"pass_data_budget_scaled_{int(round(TARGET_DURATION_S/60))}min_cumulative.png\"\n",
    "    plt.savefig(png_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Wrote cumulative plot → {png_path}\")\n",
    "\n",
    "pd.DataFrame(summaries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c827ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0e9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
